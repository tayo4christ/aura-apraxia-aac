# Multimodal AAC â€“ Makaton-Inspired Gesture-to-Speech System

This standalone prototype translates basic hand gestures into spoken phrases using real-time computer vision and offline text-to-speech (TTS). It is designed for users with speech impairments, including those with Apraxia of Speech or individuals using simplified sign languages like Makaton.

---

## âœ¨ Key Features

- Real-time **gesture detection** using webcam and MediaPipe
- Offline **text-to-speech** using `pyttsx3`
- Simple rule-based **gesture recognition**
- CSV **logging** of all recognized gestures and timestamps
- Easy-to-use and fully local â€” no internet connection required

---

## ğŸ“‚ Folder Structure

```
multimodal_aac/
â”œâ”€â”€ gesture_to_speech.py         # Main gesture recognition and TTS script
â”œâ”€â”€ gesture_config.json          # (Optional) Map gestures to spoken phrases
â”œâ”€â”€ gesture_log.csv              # Auto-generated log file for gesture history
â””â”€â”€ README.md                    # This project overview
```

---

## âš™ï¸ Requirements

Ensure Python 3.7+ is installed. Install required libraries using:

```bash
pip install opencv-python mediapipe pyttsx3
```

Also ensure that `tkinter` is available (comes pre-installed with standard Python).

---

## ğŸš€ How to Run

Launch the application using:

```bash
python gesture_to_speech.py
```

- Make a supported gesture in front of your webcam.
- The system will recognize it and speak the mapped phrase aloud.
- Press **ESC** to exit the program.

---

## ğŸ– Supported Gestures (Basic Rule-Based Logic)

| Gesture     | Recognition Logic Example                      | Spoken Output             |
|-------------|--------------------------------------------------|---------------------------|
| `hello`     | Thumb far from index                            | "Hello"                   |
| `yes`       | Thumb below index                                | "Yes, please."            |
| `no`        | Index and middle fingers close together          | "No, thank you."          |
| `stop`      | Index to the left of thumb                       | "Please stop."            |
| `goodbye`   | Index and pinky above wrist                      | "Goodbye and take care."  |

These rules can be edited in the `gesture_to_speech.py` file or dynamically loaded via `gesture_config.json`.

---

## ğŸ“ˆ Use Cases

- Alternative communication for users with Apraxia or non-verbal conditions
- Educational or therapeutic tool for language development
- Prototyping for assistive AI in EdTech and Digital Health contexts

---

## ğŸ§‘â€ğŸ’» Author

Created by **Omotayo Omoyemi**
Aimed at improving accessibility and communication for underserved user groups.

---

## ğŸ“„ License

MIT License â€” open-source and free to use, adapt, or extend.

For questions, collaborations or contributions, please connect via GitHub or LinkedIn.
